{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with Images & Logistic Regression in PyTorch\n",
    "\n",
    "In this notebook I'll be performing logistics regression on the MNIST dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root='data/', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We see there are 60,000 images in this dataset\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are instantiating the testing dataset by using train = False\n",
    "test_dataset = MNIST(root='data/', train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28 at 0x122E652E0>, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = dataset[0]\n",
    "plt.imshow(image, cmap='gray')\n",
    "print('Label: ', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The transforms module simply takes variables of differing datatypes nd transforms them into tensors\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root='data/', train=True, transform=transforms.ToTensor()) \n",
    "#Each element in the dataset is a 1 x 28 x 28 tensor where each entry is a pixel filled with its color intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 5\n"
     ]
    }
   ],
   "source": [
    "img_tensor, label = dataset[0]\n",
    "print(img_tensor.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0039, 0.6039, 0.9922, 0.3529, 0.0000],\n",
      "         [0.0000, 0.5451, 0.9922, 0.7451, 0.0078],\n",
      "         [0.0000, 0.0431, 0.7451, 0.9922, 0.2745],\n",
      "         [0.0000, 0.0000, 0.1373, 0.9451, 0.8824],\n",
      "         [0.0000, 0.0000, 0.0000, 0.3176, 0.9412]]])\n"
     ]
    }
   ],
   "source": [
    "print(img_tensor[:, 10:15, 10:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x169ff31c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Images are just matrices of pixels that can have different channels of intensity for each color\n",
    "plt.imshow(img_tensor[0, 10:15, 10:15], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Training and Validation Datasets\n",
    "While building real-world machine learning models, it is quite common to split the dataset into three parts:\n",
    "\n",
    "Training set - used to train the model, i.e., compute the loss and adjust the model's weights using gradient descent.\n",
    "Validation set - used to evaluate the model during training, adjust hyperparameters (learning rate, etc.), and pick the best version of the model.\n",
    "\n",
    "Test set - used to compare different models or approaches and report the model's final accuracy.\n",
    "In the MNIST dataset, there are 60,000 training images and 10,000 test images. The test set is standardized so that different researchers can report their models' results against the same collection of images.\n",
    "\n",
    "Since there's no predefined validation set, we must manually split the 60,000 images into training and validation datasets. Let's set aside 10,000 randomly chosen images for validation. We can do this using the random_spilt method from PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [50000, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28 * 28\n",
    "num_classes = 10\n",
    "\n",
    "model = nn.Linear(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0190,  0.0189, -0.0339,  ..., -0.0262,  0.0077,  0.0162],\n",
       "        [-0.0217, -0.0190,  0.0335,  ...,  0.0192, -0.0155,  0.0060],\n",
       "        [ 0.0292, -0.0026,  0.0290,  ...,  0.0301,  0.0251,  0.0310],\n",
       "        ...,\n",
       "        [ 0.0035, -0.0314,  0.0096,  ...,  0.0124, -0.0275,  0.0027],\n",
       "        [ 0.0253, -0.0048,  0.0270,  ..., -0.0297, -0.0003, -0.0198],\n",
       "        [-0.0110,  0.0120, -0.0104,  ...,  0.0201, -0.0043,  0.0322]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.weight.shape)\n",
    "model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#We need to reshape the 28x28 tensors for each image into a size 784 vector\\nfor images, labels in train_loader:\\n    print(images.shape)\\n    #This breaks because the images are not represented as single vectors\\n    output = model(images)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#We need to reshape the 28x28 tensors for each image into a size 784 vector\n",
    "for images, labels in train_loader:\n",
    "    print(images.shape)\n",
    "    #This breaks because the images are not represented as single vectors\n",
    "    output = model(images)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#We overcome this by using .reshape()\\nprint(images.shape)\\nimages.reshape(128, 784).shape\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#We overcome this by using .reshape()\n",
    "print(images.shape)\n",
    "images.reshape(128, 784).shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        #Since we're extending this class within another class, we have to call the constructor of the superclass first\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "    #The forward function is invoked when you pass a batch of data into the model\n",
    "    def forward(self, xb):\n",
    "        #Using the -1 allows us to use a dynamic batch size to make it more generic for\n",
    "        xb = xb.reshape(-1, 784)\n",
    "        output = self.linear(xb)\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=10, bias=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784]) torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0173,  0.0121, -0.0110,  ...,  0.0083, -0.0296,  0.0202],\n",
       "         [-0.0226, -0.0302,  0.0052,  ...,  0.0143, -0.0110,  0.0311],\n",
       "         [-0.0045,  0.0038, -0.0230,  ...,  0.0173, -0.0241,  0.0128],\n",
       "         ...,\n",
       "         [-0.0272, -0.0204, -0.0200,  ..., -0.0345, -0.0193,  0.0271],\n",
       "         [-0.0157,  0.0341,  0.0212,  ...,  0.0089, -0.0285, -0.0190],\n",
       "         [ 0.0080,  0.0127,  0.0008,  ..., -0.0111, -0.0131,  0.0295]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0256, -0.0151, -0.0345,  0.0021, -0.0348, -0.0292, -0.0038, -0.0110,\n",
       "          0.0312, -0.0255], requires_grad=True)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.linear.weight.shape, model.linear.bias.shape)\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10])\n"
     ]
    }
   ],
   "source": [
    "#Now it works!\n",
    "for images, labels in train_loader:\n",
    "    outputs = model(images)\n",
    "    print(outputs.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply soft max to each element in the output for an entry\n",
    "probs = F.softmax(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 9, 7, 8, 9, 4, 8, 3, 4, 4, 9, 4, 8, 9, 7, 7, 7, 3, 9, 7, 6, 9, 7, 3,\n",
      "        6, 7, 9, 9, 8, 9, 4, 9, 9, 9, 7, 4, 8, 6, 9, 7, 9, 9, 9, 9, 9, 7, 3, 9,\n",
      "        3, 8, 9, 7, 0, 9, 9, 9, 3, 3, 7, 9, 9, 9, 7, 0, 9, 3, 9, 7, 0, 9, 7, 4,\n",
      "        6, 9, 9, 7, 7, 7, 3, 0, 9, 7, 9, 8, 3, 1, 3, 9, 4, 9, 8, 9, 4, 9, 9, 4,\n",
      "        8, 7, 4, 9, 7, 9, 8, 3, 6, 9, 9, 7, 4, 7, 9, 4, 7, 1, 8, 9, 9, 9, 7, 4,\n",
      "        4, 7, 9, 9, 4, 7, 4, 9])\n",
      "tensor([0.1277, 0.1299, 0.1271, 0.1190, 0.1168, 0.1381, 0.1242, 0.1322, 0.1378,\n",
      "        0.1590, 0.1345, 0.1370, 0.1238, 0.1338, 0.1328, 0.1260, 0.1259, 0.1248,\n",
      "        0.1429, 0.1353, 0.1221, 0.1400, 0.1426, 0.1262, 0.1261, 0.1404, 0.1652,\n",
      "        0.1383, 0.1317, 0.1264, 0.1529, 0.1235, 0.1438, 0.1190, 0.1242, 0.1170,\n",
      "        0.1220, 0.1154, 0.1254, 0.1381, 0.1297, 0.1230, 0.1177, 0.1363, 0.1471,\n",
      "        0.1271, 0.1553, 0.1555, 0.1154, 0.1372, 0.1565, 0.1247, 0.1499, 0.1410,\n",
      "        0.1245, 0.1456, 0.1261, 0.1317, 0.1424, 0.1341, 0.1232, 0.1396, 0.1214,\n",
      "        0.1271, 0.1521, 0.1328, 0.1300, 0.1361, 0.1391, 0.1606, 0.1120, 0.1371,\n",
      "        0.1166, 0.1280, 0.1389, 0.1253, 0.1201, 0.1279, 0.1216, 0.1579, 0.1402,\n",
      "        0.1262, 0.1494, 0.1241, 0.1215, 0.1207, 0.1349, 0.1408, 0.1401, 0.1370,\n",
      "        0.1261, 0.1162, 0.1446, 0.1301, 0.1492, 0.1490, 0.1227, 0.1261, 0.1308,\n",
      "        0.1673, 0.1671, 0.1266, 0.1256, 0.1202, 0.1319, 0.1436, 0.1602, 0.1364,\n",
      "        0.1338, 0.1388, 0.1364, 0.1251, 0.1234, 0.1302, 0.1251, 0.1316, 0.1192,\n",
      "        0.1351, 0.1238, 0.1593, 0.1299, 0.1213, 0.1533, 0.1463, 0.1500, 0.1246,\n",
      "        0.1377, 0.1505], grad_fn=<MaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "max_probs, preds = torch.max(probs, dim=1)\n",
    "print(preds)\n",
    "print(max_probs)\n",
    "\n",
    "#Now we can train the model to make it learn using evaluating metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    #Returns the % of images correctly labeled\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1250)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.cross_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2756, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = loss_fn(outputs, labels) \n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training our model psuedocode\n",
    "\n",
    "#for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    #for batch in train_loader:\n",
    "        # Generate predictions\n",
    "        # Calculate loss\n",
    "        # Compute gradients\n",
    "        # Update weights\n",
    "        # Reset gradients\n",
    "    \n",
    "    # Validation phase\n",
    "    #for batch in val_loader:\n",
    "        # Generate predictions\n",
    "        # Calculate loss\n",
    "        # Calculate metrics (accuracy etc.)\n",
    "    # Calculate average validation loss & metrics\n",
    "    \n",
    "    # Log epoch, loss & metrics for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, lr, train_loader, val_loader, optfnc=torch.optim.SGD):\n",
    "\n",
    "    optimizer = optfnc(model.parameters(), lr)\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        #Training\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        #Validation\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        #Since we're extending this class within another class, we have to call the constructor of the superclass first\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "    #The forward function is invoked when you pass a batch of data into the model\n",
    "    def forward(self, xb):\n",
    "        #Using the -1 allows us to use a dynamic batch size to make it more generic for\n",
    "        xb = xb.reshape(-1, 784)\n",
    "        output = self.linear(xb)\n",
    "        return output\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        #self(images) calls the forward functiion, which returns the output\n",
    "        out = self(images)                  #Generates Predictions using self() as the model\n",
    "        loss = F.cross_entropy(out, labels) #Generates loss of these predictions\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)                  #Generate Predictions\n",
    "        loss = F.cross_entropy(out, labels) #Calculate Loss\n",
    "        acc = accuracy(out, labels)         #Calculate Accuracy\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'macOS-12.3.1-arm64-arm-64bit'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import platform\n",
    "platform.platform()\n",
    "#Ensuring we are using GPU to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.has_mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the device to use\n",
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating device w/ GPU\n",
    "model = MNISTModel()\n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 2.3406834602355957, 'val_acc': 0.15150316059589386}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result0 = evaluate(model, val_loader)\n",
    "result0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 1.9700, val_acc: 0.5659\n",
      "Epoch [1], val_loss: 1.6998, val_acc: 0.6853\n",
      "Epoch [2], val_loss: 1.4978, val_acc: 0.7459\n",
      "Epoch [3], val_loss: 1.3450, val_acc: 0.7715\n",
      "Epoch [4], val_loss: 1.2274, val_acc: 0.7895\n"
     ]
    }
   ],
   "source": [
    "history1 = fit(5, .001, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 1.1350, val_acc: 0.8002\n",
      "Epoch [1], val_loss: 1.0607, val_acc: 0.8091\n",
      "Epoch [2], val_loss: 0.9999, val_acc: 0.8164\n",
      "Epoch [3], val_loss: 0.9492, val_acc: 0.8221\n",
      "Epoch [4], val_loss: 0.9064, val_acc: 0.8259\n"
     ]
    }
   ],
   "source": [
    "history2 = fit(5, .001, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 0.8697, val_acc: 0.8296\n",
      "Epoch [1], val_loss: 0.8379, val_acc: 0.8320\n",
      "Epoch [2], val_loss: 0.8102, val_acc: 0.8357\n",
      "Epoch [3], val_loss: 0.7856, val_acc: 0.8390\n",
      "Epoch [4], val_loss: 0.7637, val_acc: 0.8413\n"
     ]
    }
   ],
   "source": [
    "history3 = fit(5, .001, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 0.7442, val_acc: 0.8431\n",
      "Epoch [1], val_loss: 0.7264, val_acc: 0.8455\n",
      "Epoch [2], val_loss: 0.7104, val_acc: 0.8474\n",
      "Epoch [3], val_loss: 0.6958, val_acc: 0.8500\n",
      "Epoch [4], val_loss: 0.6824, val_acc: 0.8514\n"
     ]
    }
   ],
   "source": [
    "history4 = fit(5, .001, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy vs. # Epochs')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = history1 + history2 + history3 + history4\n",
    "accuracies = [result['val_acc'] for result in history]\n",
    "plt.plot(accuracies, '-x')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Accuracy vs. # Epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Creating a new project \"danielcufino/3-logistic-regression\"\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ai/danielcufino/3-logistic-regression\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ai/danielcufino/3-logistic-regression'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jovian\n",
    "jovian.commit(filename='3-logistic-regression.ipynb', project='3-logistic-regression', environment = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Metrics logged.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "jovian.log_metrics(val_acc=history[-1]['val_acc'], val_loss=history[-1]['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MNIST(root='data/', \n",
    "                        train=False, \n",
    "                        transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([1, 28, 28])\n",
      "Label: \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[0]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('Shape: {}'.format(img.shape))\n",
    "print('Label: '.format(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img, model):\n",
    "    #unsqueeze adds an an image to our data since our model has to always take in batches, even of size 1\n",
    "    xb = img.unsqueeze(0)\n",
    "    yb = model(xb)\n",
    "    #get the index of the highest value element\n",
    "    _, preds = torch.max(yb, dim=1)\n",
    "    #.item() extracts the value out of a tensor\n",
    "    return preds[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: \n",
      "Predicted: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[0]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('Label: '.format(label))\n",
    "print('Predicted: {}'.format(predict_image(img, model)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.6451002955436707, 'val_acc': 0.858691394329071}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=256)\n",
    "result = evaluate(model, test_loader)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hpw to save a model\n",
    "torch.save(model.state_dict(), 'mnist_logistic.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight',\n",
       "              tensor([[-0.0179,  0.0086, -0.0332,  ...,  0.0276, -0.0221,  0.0259],\n",
       "                      [-0.0218, -0.0285,  0.0067,  ..., -0.0115,  0.0087, -0.0088],\n",
       "                      [-0.0250,  0.0262,  0.0012,  ...,  0.0082, -0.0336,  0.0185],\n",
       "                      ...,\n",
       "                      [-0.0004, -0.0212,  0.0276,  ...,  0.0143, -0.0329,  0.0291],\n",
       "                      [ 0.0122,  0.0335,  0.0001,  ...,  0.0273,  0.0014, -0.0262],\n",
       "                      [-0.0152,  0.0075,  0.0042,  ...,  0.0182,  0.0275, -0.0176]])),\n",
       "             ('linear.bias',\n",
       "              tensor([-0.0332,  0.0739, -0.0033, -0.0066, -0.0003,  0.0581, -0.0277,  0.0342,\n",
       "                      -0.1120, -0.0097]))])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to load a model\n",
    "model2 = MNISTModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.6451002955436707, 'val_acc': 0.858691394329071}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.load_state_dict(torch.load('mnist_logistic.pth'))\n",
    "result = evaluate(model2, test_loader)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jovian.commit(filename='3-logistic-regression.ipynb', \n",
    "                project='3-logistic-regression', \n",
    "                environment = None,\n",
    "                outputs=['mnist_logistic.pth'])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6029c3e4a5bf2fd888ebd83fdb88a6c4178759d2e9deacc90d4e0ec196249d32"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
